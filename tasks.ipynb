{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8bda8637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            msg_type             datetime  \\\n",
      "0       thread_start  2018-01-01 00:00:00   \n",
      "162     thread_start  2018-01-01 00:00:05   \n",
      "466     thread_start  2018-01-01 00:01:40   \n",
      "473     thread_start  2018-01-01 00:01:59   \n",
      "738     thread_start  2018-01-01 00:07:08   \n",
      "...              ...                  ...   \n",
      "344338  thread_start  2018-01-24 14:06:46   \n",
      "344343  thread_start  2018-01-24 14:07:07   \n",
      "344344  thread_start  2018-01-24 14:08:01   \n",
      "344345  thread_start  2018-01-24 14:08:34   \n",
      "344347  thread_start  2018-01-24 14:08:51   \n",
      "\n",
      "                                                    title  thread_id  \\\n",
      "0                                 Unohda en sinua koskaan   15127813   \n",
      "162                     Hyvää Uutta Vuotta 2018 Kaikille!   15127814   \n",
      "466                               Onnellista vuotta 2018!   15127815   \n",
      "473                                    En Äänestä Larikaa   15127816   \n",
      "738                                    Onko tosiaan niin,   15127818   \n",
      "...                                                   ...        ...   \n",
      "344338               Venäjä aloitti uudellen kylmän sodan   15158279   \n",
      "344343  JanneAhonen sai ilmaisen turistimatkanEteläKor...   15158280   \n",
      "344344  Onnistuu se Putinin kravatin kohentaminen Laur...   15158281   \n",
      "344345                                    Työtä tarjolla!   15158282   \n",
      "344347  Huhtasaari: EU:n ohjaama hullu petopolitiikka ...   15158283   \n",
      "\n",
      "        comment_id topic_name_top   topic_name_leaf  \\\n",
      "0                0        Suhteet           Tunteet   \n",
      "162              0    Yhteiskunta     Luterilaisuus   \n",
      "466              0    Yhteiskunta        Adventismi   \n",
      "473              0   Paikkakunnat           Kouvola   \n",
      "738              0    Yhteiskunta       Yhteiskunta   \n",
      "...            ...            ...               ...   \n",
      "344338           0    Yhteiskunta    Maailman menoa   \n",
      "344343           0    Yhteiskunta    Maailman menoa   \n",
      "344344           0    Yhteiskunta  Perussuomalaiset   \n",
      "344345           0   Paikkakunnat           Paltamo   \n",
      "344347           0    Yhteiskunta    Maailman menoa   \n",
      "\n",
      "                                              thread_text  \n",
      "0       Unohda en sinua koskaan nainen . En vain pysty...  \n",
      "162     Hyvää Uutta Vuotta 2018 Kaikille ! Suomi on me...  \n",
      "466     Onnellista vuotta 2018 ! Siunausta kaikille vu...  \n",
      "473     En Äänestä Larikaa Uudenvuodenlupauksen . Ääni...  \n",
      "738     Onko tosiaan niin , että ulkomaalainen saa häi...  \n",
      "...                                                   ...  \n",
      "344338  Venäjä aloitti uudellen kylmän sodan No nyt Ve...  \n",
      "344343  JanneAhonen sai ilmaisen turistimatkanEteläKor...  \n",
      "344344  Onnistuu se Putinin kravatin kohentaminen Laur...  \n",
      "344345  Työtä tarjolla ! \" Haluatko ansaita kotona ? M...  \n",
      "344347  Huhtasaari : EU:n ohjaama hullu petopolitiikka...  \n",
      "\n",
      "[22173 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#nltk.download('punkt')\n",
    "\n",
    "# Declare the selected keyword\n",
    "selected_keyword = [\"well-being\"]  # Initial value\n",
    "translations = [\"hyvinvointi\", \"vointi\"]\n",
    "translations = translations + selected_keyword\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv('data/parsed_data_sample.csv')\n",
    "# Filter out only threads\n",
    "threads_df = df[df['msg_type'] == 'thread_start']\n",
    "print (threads_df)\n",
    "\n",
    "# Function to check if the keyword is in the text\n",
    "def contains_keyword(text):\n",
    "    tokens = word_tokenize(text.lower())  # Convert text to lowercase for case-insensitive matching\n",
    "    return any(translation in tokens for translation in translations)\n",
    "\n",
    "# Filter threads containing the keyword in title or thread_text\n",
    "filtered_threads = threads_df[threads_df['title'].apply(contains_keyword) | threads_df['thread_text'].apply(contains_keyword)]\n",
    "\n",
    "# Save the filtered results to a new CSV file\n",
    "filtered_threads[['title', 'thread_text', 'datetime']].to_csv('data/filtered_threads.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4a92a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year dat2001: Vocabulary Size = 0\n",
      "Year dat2002: Vocabulary Size = 0\n",
      "Year dat2003: Vocabulary Size = 0\n",
      "Year dat2004: Vocabulary Size = 0\n",
      "Year dat2005: Vocabulary Size = 0\n",
      "Year dat2006: Vocabulary Size = 0\n",
      "Year dat2007: Vocabulary Size = 0\n",
      "Year dat2008: Vocabulary Size = 0\n",
      "Year dat2009: Vocabulary Size = 0\n",
      "Year dat2010: Vocabulary Size = 0\n",
      "Year dat2011: Vocabulary Size = 0\n",
      "Year dat2012: Vocabulary Size = 0\n",
      "Year dat2013: Vocabulary Size = 0\n",
      "Year dat2014: Vocabulary Size = 0\n",
      "Year dat2015: Vocabulary Size = 0\n",
      "Year dat2016: Vocabulary Size = 0\n",
      "Year dat2017: Vocabulary Size = 0\n",
      "Year dat2018: Vocabulary Size = 1899\n"
     ]
    }
   ],
   "source": [
    "#Section 2\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data/filtered_threads.csv')  # Replace with the path to your dataset\n",
    "\n",
    "# Function to extract the year from the 'datetime' column\n",
    "def extract_year(date_string):\n",
    "    return int(date_string[:4])\n",
    "\n",
    "# Create a dictionary to store sub-datasets for each year\n",
    "yearly_datasets = {}\n",
    "\n",
    "# Loop through the dataset and separate data for each year\n",
    "for year in range(2001, 2019):\n",
    "    # Filter data for the current year\n",
    "    data_for_year = df[df['datetime'].apply(lambda x: extract_year(x) == year)]\n",
    "    yearly_datasets[f'dat{year}'] = data_for_year\n",
    "\n",
    "# Function to calculate vocabulary for each year\n",
    "def get_vocabulary(data):\n",
    "    tokens = []\n",
    "    for text in data['thread_text']:\n",
    "        if isinstance(text, str):  # Check if text is a valid string\n",
    "            text = text.lower()  # Convert to lowercase for consistency\n",
    "            tokens.extend(word_tokenize(text))\n",
    "    fdist = FreqDist(tokens)\n",
    "    return fdist  # Use FreqDist to get word frequencies\n",
    "\n",
    "# Create a dictionary to store the vocabulary for each year\n",
    "vocabulary_by_year = {}\n",
    "\n",
    "# Calculate vocabulary for each year\n",
    "for year, data in yearly_datasets.items():\n",
    "    year_vocabulary = get_vocabulary(data)\n",
    "    vocabulary_by_year[year] = year_vocabulary\n",
    "\n",
    "# Print or manipulate the vocabulary data as needed\n",
    "for year, vocab in vocabulary_by_year.items():\n",
    "    print(f\"Year {year}: Vocabulary Size = {len(vocab)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
